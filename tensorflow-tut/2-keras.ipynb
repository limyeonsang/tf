{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras의 모델 개발과정\n",
    "1.  ```python\n",
    "    model = Sequential()\n",
    "    model.add(~~)\n",
    "    model.add(~~)\n",
    "    ~~\n",
    "    ```\n",
    "2. ```model.compile()```   \n",
    "\n",
    "\n",
    "3. ```model.fit()```\n",
    "\n",
    " \n",
    "4.  ```\n",
    "    model.evaluate()\n",
    "    model.predict()\n",
    "    ```\n",
    "    \n",
    "5. ```model.save()```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과정 1\n",
    "\n",
    "![](./resource/model.png)\n",
    "\n",
    "```\n",
    "model=Sequential()\n",
    "model.add(Flatten(input_shape=(1,))) # 입력층\n",
    "model.add(Dense(2, activation='sigmoid)) # 은닉층\n",
    "model.add(Dense(1, activation='sigmoid)) # 출력층\n",
    "```\n",
    "\n",
    "\n",
    "- Flatten: 입력으로 들어오는 다차원 데이터를 1차원으로 정렬하기 위해 사용되는 레이어, 입력 데이터의 차원수를 input_shape=(1,)과 같이 기술\n",
    "- Dense: 완전 연결 층을 나타내며, 첫번째 인자는 출력의 수를 나타낸다. \n",
    "    - 노드의 활성화 함수는 activation= 형태로 나타내며 선형='linear', 이진 분류='sigmoid', 분류='softmax, relu, tanh'이 있다. \n",
    "    - 첫번째 layer에 바로 Dense를 사용한다면 Dense에서 input_shape=(1,)을 이용해 한줄로 나타낼 수 있다.    \n",
    "    ```model.add(Dense(2, activation='sigmoid', input_shape=(1,)))```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과정 2\n",
    "\n",
    "model compile\n",
    "```\n",
    "model.compile(optimizer=SGD(learning_rate=0.1), loss='mse', metrics=['accuracy']) # ex1\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy) # ex2\n",
    "```\n",
    "\n",
    "model fit\n",
    "```\n",
    "model.fit(x_train, y_test , epochs=10, batch_size=100, verbose=0, validation_split=0,2)\n",
    "# validation_split: 학습데이터의 20%를 검정데이터로 사용 *검정데이터가 별도로 있다면, validation_data를 이용해 지정 가능\n",
    "# verbose: (0,1,2) 학습 중 손실 값, 정확도, 진행 상태 등의 출력 형태를 설정\n",
    "```\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과정 3\n",
    "\n",
    "model evaluate\n",
    "```\n",
    "model.evaluate(x_test, y_test, epochs=10, batch_size=100)\n",
    "```\n",
    "\n",
    "model predict\n",
    "```\n",
    "model.predict(예측하고자 하는 데이터, batch_size=100)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과정 4\n",
    "\n",
    "학습이 끝난(가중치와 바이어스가 최적화된) 신경망 구조를 저장해, 다양한 테스트 데이터에 대해 재 학습 없이 지속적으로 사용한다. \n",
    "\n",
    "model save\n",
    "```\n",
    "model.save('~~.h5')\n",
    "```\n",
    "\n",
    "model load\n",
    "```\n",
    "model = tf.keras.models.load_model('~~.h5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple linear regression exercise\n",
    "\n",
    "![](./resource/model2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([1,2,3,4,5,6])\n",
    "y_data = np.array([3,4,5,6,7,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten(input_shape=(1,)))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=SGD(learning_rate=1e-2), loss='mse')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 127.7059\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 59.2941\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 27.6298\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.9732\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.1883\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0468\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5914\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9165\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6028\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4564\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3873\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3540\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3373\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3284\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3230\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3192\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3162\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3136\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3112\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3089\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3066\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3044\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3021\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2999\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2977\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2956\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2934\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2913\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2892\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2870\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2850\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2829\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2808\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2788\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2767\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2747\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2727\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2707\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2688\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2668\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2649\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2629\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2610\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2591\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2572\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2554\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2535\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2516\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2498\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2480\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2462\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2444\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2426\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2408\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2391\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2373\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2356\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2339\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2322\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2305\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2288\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2272\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2255\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2239\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2222\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2206\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2190\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2174\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2158\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2143\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2127\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2111\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2096\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2081\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2066\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2051\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2036\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2021\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2006\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1991\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1977\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1963\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1948\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1934\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1920\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1906\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1892\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1878\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1865\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1851\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1838\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1824\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1811\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1798\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1785\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1772\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1759\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1746\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1733\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1721\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_data, y_data, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.1080284],\n",
       "       [16.552645 ],\n",
       "       [ 3.4979982],\n",
       "       [23.384983 ],\n",
       "       [10.208331 ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.predict(np.array([2.5, 12.7, 2.0, 18.3, 7.5]))\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "762568b60ff02034ad30f76ec13eabb79a0decfbc2d9faa7bfbe9062055c30a3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('tf-K1gCNad0': pipenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
